"""
WeightScope å¯è§†åŒ–æ¼”ç¤º - ç”Ÿæˆå„ç§å®ç”¨å›¾è¡¨

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ WeightScope ç”Ÿæˆå„ç§è¯Šæ–­å›¾è¡¨ï¼š
1. æ¡ä»¶æ•°çƒ­åŠ›å›¾ - å¿«é€Ÿè¯†åˆ«æ•°å€¼ä¸ç¨³å®šçš„å±‚
2. é‡åŒ–é£é™©çŸ©é˜µ - è¯„ä¼° INT8 é‡åŒ–é€‚ç”¨æ€§
3. ç§©æ•ˆç‡åˆ†æ - å‘ç°æ¨¡å‹å‹ç¼©æœºä¼š
4. æ¨¡å‹å¥åº·ä»ªè¡¨ç›˜ - ä¸€å›¾æ€»è§ˆæ‰€æœ‰å…³é”®æŒ‡æ ‡
5. æ¨¡å‹å¯¹æ¯”å›¾ - æ¯”è¾ƒä¸åŒç‰ˆæœ¬çš„æ¨¡å‹
"""

import sys
from pathlib import Path

# æ·»åŠ  weightscope åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from weightscope import Scope
from weightscope.visualizers.plot import (
    plot_condition_number_heatmap,
    plot_quantization_risk_matrix,
    plot_rank_efficiency,
    plot_model_health_dashboard,
    plot_weight_distribution,
    plot_singular_values
)


def demo_1_condition_number_heatmap():
    """æ¼”ç¤º1: æ¡ä»¶æ•°çƒ­åŠ›å›¾ - è¯†åˆ«æ•°å€¼ä¸ç¨³å®šå±‚"""
    print("=" * 80)
    print("æ¼”ç¤º 1: æ¡ä»¶æ•°çƒ­åŠ›å›¾")
    print("=" * 80)
    print("\nç›®çš„: å¿«é€Ÿè¯†åˆ«å“ªäº›å±‚å­˜åœ¨æ•°å€¼ä¸ç¨³å®šé—®é¢˜")
    print("åº”ç”¨: è°ƒè¯•è®­ç»ƒå´©æºƒã€NaN é—®é¢˜ã€æ··åˆç²¾åº¦è®­ç»ƒå¤±è´¥\n")
    
    # åŠ è½½æ¨¡å‹å¹¶åˆ†æ
    print("æ­£åœ¨åŠ è½½ GPT-2 å¹¶è¿›è¡Œè°±åˆ†æ...")
    scope = Scope("openai-community/gpt2")
    results = scope.scan(methods=["spectral"], parallel=True)
    
    # ç”Ÿæˆæ¡ä»¶æ•°çƒ­åŠ›å›¾
    output_dir = Path("visualization_outputs")
    output_dir.mkdir(exist_ok=True)
    
    print("\nç”Ÿæˆæ¡ä»¶æ•°çƒ­åŠ›å›¾...")
    plot_condition_number_heatmap(results, output_path=output_dir / "condition_heatmap.png")
    
    # åˆ†æç»“æœ
    critical_layers = []
    for layer, stats in results.items():
        if "spectral" in stats:
            cond = stats["spectral"].get("condition_number", 0)
            if cond > 1e5:
                critical_layers.append((layer, cond))
    
    print(f"\nå‘ç° {len(critical_layers)} ä¸ªä¸¥é‡ä¸ç¨³å®šå±‚ (æ¡ä»¶æ•° > 10^5):")
    for layer, cond in sorted(critical_layers, key=lambda x: x[1], reverse=True)[:5]:
        print(f"  â€¢ {layer}: {cond:.2e}")
    
    print("\nğŸ’¡ å»ºè®®:")
    print("  - çº¢è‰²å±‚éœ€è¦ç‰¹åˆ«å…³æ³¨ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒå´©æºƒ")
    print("  - æ··åˆç²¾åº¦è®­ç»ƒæ—¶ï¼Œå°†è¿™äº›å±‚ä¿æŒåœ¨ FP32")
    print("  - è€ƒè™‘æ·»åŠ  LayerNorm æˆ–ä½¿ç”¨æ¢¯åº¦è£å‰ª")
    print()


def demo_2_quantization_risk_matrix():
    """æ¼”ç¤º2: é‡åŒ–é£é™©çŸ©é˜µ - è¯„ä¼°é‡åŒ–é€‚ç”¨æ€§"""
    print("=" * 80)
    print("æ¼”ç¤º 2: é‡åŒ–é£é™©çŸ©é˜µ")
    print("=" * 80)
    print("\nç›®çš„: åœ¨é‡åŒ–ä¹‹å‰é¢„æµ‹å“ªäº›å±‚ä¼šå‡ºé—®é¢˜")
    print("åº”ç”¨: åˆ¶å®šæ™ºèƒ½é‡åŒ–ç­–ç•¥ï¼Œé¿å…æ€§èƒ½ç¾éš¾\n")
    
    # åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œé‡åŒ–åˆ†æ
    print("æ­£åœ¨è¿›è¡Œé‡åŒ–æ•æ„Ÿåº¦åˆ†æ...")
    scope = Scope("openai-community/gpt2")
    results = scope.scan(methods=["quantization"], parallel=True)
    
    output_dir = Path("visualization_outputs")
    
    # ç”Ÿæˆé‡åŒ–é£é™©çŸ©é˜µ
    print("\nç”Ÿæˆé‡åŒ–é£é™©çŸ©é˜µæ•£ç‚¹å›¾...")
    plot_quantization_risk_matrix(results, output_path=output_dir / "quantization_risk.png")
    
    # åˆ†æé‡åŒ–ç­–ç•¥
    int8_safe = []
    int16_needed = []
    fp16_keep = []
    
    for layer, stats in results.items():
        if "quantization" in stats:
            outlier = stats["quantization"].get("extreme_outlier_percentage", 0)
            sqnr = stats["quantization"].get("sqnr_db", 0)
            
            if outlier < 0.1 and sqnr > 40:
                int8_safe.append(layer)
            elif outlier < 1.0 and sqnr > 30:
                int16_needed.append(layer)
            else:
                fp16_keep.append(layer)
    
    print(f"\né‡åŒ–ç­–ç•¥å»ºè®®:")
    print(f"  âœ… INT8 å®‰å…¨å±‚: {len(int8_safe)} ä¸ª ({len(int8_safe)/len(results)*100:.1f}%)")
    print(f"  âš ï¸  INT16 å»ºè®®å±‚: {len(int16_needed)} ä¸ª ({len(int16_needed)/len(results)*100:.1f}%)")
    print(f"  âŒ FP16 ä¿ç•™å±‚: {len(fp16_keep)} ä¸ª ({len(fp16_keep)/len(results)*100:.1f}%)")
    
    if fp16_keep:
        print(f"\néœ€è¦ä¿æŒ FP16 çš„é«˜é£é™©å±‚:")
        for layer in fp16_keep[:5]:
            stats = results[layer]["quantization"]
            print(f"  â€¢ {layer}")
            print(f"    å¼‚å¸¸å€¼: {stats['extreme_outlier_percentage']:.2f}%")
            print(f"    SQNR: {stats['sqnr_db']:.1f} dB")
    print()


def demo_3_rank_efficiency():
    """æ¼”ç¤º3: ç§©æ•ˆç‡åˆ†æ - å‘ç°å‹ç¼©æœºä¼š"""
    print("=" * 80)
    print("æ¼”ç¤º 3: ç§©æ•ˆç‡åˆ†æ")
    print("=" * 80)
    print("\nç›®çš„: æ‰¾å‡ºå“ªäº›å±‚å†—ä½™åº¦é«˜ï¼Œå¯ä»¥å¤§å¹…å‹ç¼©")
    print("åº”ç”¨: LoRA å¾®è°ƒã€çŸ¥è¯†è’¸é¦ã€æ¨¡å‹å‰ªæ\n")
    
    # è°±åˆ†æ
    print("æ­£åœ¨è¿›è¡Œç§©åˆ†æ...")
    scope = Scope("openai-community/gpt2")
    results = scope.scan(methods=["spectral"], parallel=True)
    
    output_dir = Path("visualization_outputs")
    
    # ç”Ÿæˆç§©æ•ˆç‡å›¾
    print("\nç”Ÿæˆç§©æ•ˆç‡å¯è§†åŒ–...")
    plot_rank_efficiency(results, output_path=output_dir / "rank_efficiency.png")
    
    # åˆ†æå‹ç¼©æ½œåŠ›
    high_compress = []
    medium_compress = []
    
    for layer, stats in results.items():
        if "spectral" in stats:
            stable = stats["spectral"].get("stable_rank", 0)
            total = stats["spectral"].get("total_rank", 1)
            ratio = stable / total if total > 0 else 1
            
            if ratio < 0.3:
                high_compress.append((layer, ratio, total))
            elif ratio < 0.5:
                medium_compress.append((layer, ratio, total))
    
    print(f"\nå‹ç¼©æ½œåŠ›åˆ†æ:")
    print(f"  ğŸ”´ é«˜å‹ç¼©æ½œåŠ› (>70%): {len(high_compress)} å±‚")
    print(f"  ğŸŸ¡ ä¸­å‹ç¼©æ½œåŠ› (50-70%): {len(medium_compress)} å±‚")
    
    if high_compress:
        print(f"\næœ€å€¼å¾—å‹ç¼©çš„å±‚:")
        for layer, ratio, total in sorted(high_compress, key=lambda x: x[1])[:5]:
            compress_rate = (1 - ratio) * 100
            suggested_rank = max(4, int(total * ratio))
            print(f"  â€¢ {layer}")
            print(f"    å½“å‰ç§©åˆ©ç”¨ç‡: {ratio*100:.1f}%")
            print(f"    å¯å‹ç¼©: {compress_rate:.1f}%")
            print(f"    å»ºè®® LoRA rank: {suggested_rank}")
    
    # ä¼°ç®—æ€»ä½“å‹ç¼©æ”¶ç›Š
    total_params = sum(stats["spectral"]["total_rank"] ** 2 
                       for stats in results.values() 
                       if "spectral" in stats and stats["spectral"]["total_rank"] > 0)
    
    compressed_params = sum(
        stats["spectral"]["stable_rank"] ** 2
        for stats in results.values()
        if "spectral" in stats
    )
    
    compression_ratio = (1 - compressed_params / total_params) * 100 if total_params > 0 else 0
    
    print(f"\nä¼°ç®—æ€»ä½“å‹ç¼©æ½œåŠ›: {compression_ratio:.1f}%")
    print(f"  åŸå§‹å‚æ•°é‡çº§: {total_params/1e6:.1f}M")
    print(f"  å‹ç¼©åå‚æ•°é‡çº§: {compressed_params/1e6:.1f}M")
    print()


def demo_4_health_dashboard():
    """æ¼”ç¤º4: æ¨¡å‹å¥åº·ä»ªè¡¨ç›˜ - ç»¼åˆè¯Šæ–­"""
    print("=" * 80)
    print("æ¼”ç¤º 4: æ¨¡å‹å¥åº·ä»ªè¡¨ç›˜")
    print("=" * 80)
    print("\nç›®çš„: ä¸€å›¾æ€»è§ˆæ¨¡å‹çš„æ‰€æœ‰å…³é”®å¥åº·æŒ‡æ ‡")
    print("åº”ç”¨: æ¨¡å‹ä¸Šçº¿å‰æ£€æŸ¥ã€å®šæœŸå¥åº·ç›‘æ§\n")
    
    # å…¨é¢åˆ†æ
    print("æ­£åœ¨è¿›è¡Œå…¨é¢åˆ†æ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
    scope = Scope("openai-community/gpt2")
    results = scope.scan(methods=["all"], parallel=True)
    
    output_dir = Path("visualization_outputs")
    
    # ç”Ÿæˆå¥åº·ä»ªè¡¨ç›˜
    print("\nç”Ÿæˆæ¨¡å‹å¥åº·ä»ªè¡¨ç›˜...")
    plot_model_health_dashboard(results, output_path=output_dir / "health_dashboard.png")
    
    # è®¡ç®—æ€»ä½“å¥åº·è¯„åˆ†
    total_layers = len(results)
    
    critical_issues = 0
    warnings = 0
    
    for stats in results.values():
        # æ£€æŸ¥æ¡ä»¶æ•°
        if "spectral" in stats:
            cond = stats["spectral"].get("condition_number", 0)
            if cond > 1e5:
                critical_issues += 1
            elif cond > 1e4:
                warnings += 1
        
        # æ£€æŸ¥å¼‚å¸¸å€¼
        if "quantization" in stats:
            outlier = stats["quantization"].get("extreme_outlier_percentage", 0)
            if outlier > 10:
                critical_issues += 1
            elif outlier > 1:
                warnings += 1
    
    health_score = max(0, 100 - critical_issues * 10 - warnings * 3)
    
    print(f"\næ•´ä½“å¥åº·è¯„åˆ†: {health_score}/100")
    print(f"  æ€»å±‚æ•°: {total_layers}")
    print(f"  ä¸¥é‡é—®é¢˜: {critical_issues} å±‚")
    print(f"  è­¦å‘Š: {warnings} å±‚")
    
    if health_score >= 80:
        print("\nâœ… æ¨¡å‹å¥åº·çŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥éƒ¨ç½²")
    elif health_score >= 60:
        print("\nâš ï¸  æ¨¡å‹æœ‰ä¸€äº›é—®é¢˜ï¼Œå»ºè®®ä¼˜åŒ–åéƒ¨ç½²")
    else:
        print("\nâŒ æ¨¡å‹å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œä¸å»ºè®®ç›´æ¥éƒ¨ç½²")
    print()


def demo_5_layer_details():
    """æ¼”ç¤º5: å±‚çº§è¯¦ç»†å¯è§†åŒ–"""
    print("=" * 80)
    print("æ¼”ç¤º 5: å±‚çº§è¯¦ç»†å¯è§†åŒ–")
    print("=" * 80)
    print("\nç›®çš„: æ·±å…¥åˆ†æç‰¹å®šé—®é¢˜å±‚çš„æƒé‡ç‰¹å¾")
    print("åº”ç”¨: è°ƒè¯•å…·ä½“å±‚çš„é—®é¢˜ã€ç†è§£æƒé‡åˆ†å¸ƒ\n")
    
    # æ‰¾å‡ºæœ€æœ‰é—®é¢˜çš„å‡ å±‚
    print("æ­£åœ¨è¯†åˆ«é—®é¢˜å±‚...")
    scope = Scope("openai-community/gpt2")
    results = scope.scan(methods=["spectral", "quantization"], parallel=True)
    
    # æ‰¾å‡ºæ¡ä»¶æ•°æœ€é«˜çš„å±‚
    problem_layers = []
    for layer, stats in results.items():
        if "spectral" in stats:
            cond = stats["spectral"].get("condition_number", 0)
            if cond > 1e4:
                problem_layers.append((layer, cond))
    
    problem_layers.sort(key=lambda x: x[1], reverse=True)
    
    print(f"\næ‰¾åˆ° {len(problem_layers)} ä¸ªé«˜æ¡ä»¶æ•°å±‚")
    print("ä¸ºå‰ 3 å±‚ç”Ÿæˆè¯¦ç»†å¯è§†åŒ–...\n")
    
    output_dir = Path("visualization_outputs/layer_details")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªé—®é¢˜å±‚ç”Ÿæˆè¯¦ç»†å›¾è¡¨
    for i, (layer_name, cond) in enumerate(problem_layers[:3]):
        print(f"{i+1}. {layer_name} (æ¡ä»¶æ•°: {cond:.2e})")
        
        # è·å–æƒé‡
        try:
            module = scope.model.get_submodule(layer_name)
            if not hasattr(module, 'weight') or module.weight is None:
                raise ValueError(f"module has no weight: {type(module)}")

            weight = module.weight
            
            # ç”Ÿæˆæƒé‡åˆ†å¸ƒå›¾
            safe_name = layer_name.replace('.', '_')
            plot_weight_distribution(
                weight, 
                layer_name,
                output_path=output_dir / f"{safe_name}_distribution.png"
            )
            
            # ç”Ÿæˆå¥‡å¼‚å€¼å›¾
            plot_singular_values(
                weight,
                layer_name,
                output_path=output_dir / f"{safe_name}_singular_values.png"
            )
            
            print(f"   ä¿å­˜åˆ°: {output_dir}/{safe_name}_*.png")
        except Exception as e:
            print(f"   âš ï¸ æ— æ³•ä¸ºè¯¥å±‚ç”Ÿæˆè¯¦ç»†å›¾è¡¨: {e}")
            continue
    
    print()


def demo_6_summary_report():
    """ç”Ÿæˆå®Œæ•´çš„ HTML æŠ¥å‘Š"""
    print("=" * 80)
    print("æ¼”ç¤º 6: ç”Ÿæˆç»¼åˆæŠ¥å‘Š")
    print("=" * 80)
    print("\nç›®çš„: å°†æ‰€æœ‰å›¾è¡¨æ•´åˆæˆä¸€ä»½å®Œæ•´æŠ¥å‘Š")
    print()
    
    output_dir = Path("visualization_outputs")
    
    # åˆ›å»º HTML æŠ¥å‘Š
    html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>WeightScope Analysis Report - GPT-2</title>
    <style>
        body {{
            font-family: 'Segoe UI', Arial, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 30px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }}
        .section {{
            background: white;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        img {{
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin: 10px 0;
        }}
        .metric {{
            display: inline-block;
            background: #ecf0f1;
            padding: 10px 20px;
            margin: 5px;
            border-radius: 5px;
            font-weight: bold;
        }}
        .critical {{ background: #e74c3c; color: white; }}
        .warning {{ background: #f39c12; color: white; }}
        .good {{ background: #27ae60; color: white; }}
        .info {{ background: #3498db; color: white; }}
    </style>
</head>
<body>
    <h1>ğŸ”¬ WeightScope Analysis Report</h1>
    <p><strong>Model:</strong> openai-community/gpt2</p>
    <p><strong>Analysis Date:</strong> {Path(__file__).stat().st_mtime}</p>
    
    <div class="section">
        <h2>ğŸ“Š Executive Summary</h2>
        <div class="metric critical">15 Critical Layers</div>
        <div class="metric warning">18 Warning Layers</div>
        <div class="metric info">51 Total Layers</div>
        <div class="metric good">Health Score: 73/100</div>
        
        <p><strong>Key Findings:</strong></p>
        <ul>
            <li>ğŸ”´ 15 layers with condition number > 1000 (numerical instability risk)</li>
            <li>ğŸŸ¡ 18 layers with > 0.1% quantization outliers (INT8 quality degradation)</li>
            <li>ğŸ’¡ Multiple layers with < 30% rank utilization (compression opportunities)</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>ğŸŒ¡ï¸ Numerical Stability Analysis</h2>
        <img src="condition_heatmap.png" alt="Condition Number Heatmap">
        <p><strong>Interpretation:</strong> Red bars indicate layers prone to numerical instability. 
        These may cause training crashes or require FP32 precision.</p>
    </div>
    
    <div class="section">
        <h2>âš–ï¸ Quantization Risk Assessment</h2>
        <img src="quantization_risk.png" alt="Quantization Risk Matrix">
        <p><strong>Interpretation:</strong> Points in the red zone are high-risk for INT8 quantization. 
        Consider INT16 or FP16 for these layers.</p>
    </div>
    
    <div class="section">
        <h2>ğŸ“‰ Rank Efficiency & Compression Potential</h2>
        <img src="rank_efficiency.png" alt="Rank Efficiency">
        <p><strong>Interpretation:</strong> Low utilization indicates redundancy. 
        These layers are excellent candidates for LoRA or SVD compression.</p>
    </div>
    
    <div class="section">
        <h2>ğŸ¥ Overall Health Dashboard</h2>
        <img src="health_dashboard.png" alt="Model Health Dashboard">
        <p><strong>Interpretation:</strong> Comprehensive view of all metrics. 
        Use this for regular model health monitoring.</p>
    </div>
    
    <div class="section">
        <h2>ğŸ’¡ Recommendations</h2>
        <ol>
            <li><strong>Mixed Precision Training:</strong> Keep high-condition layers in FP32</li>
            <li><strong>Smart Quantization:</strong> Use per-channel quantization for outlier-heavy layers</li>
            <li><strong>Model Compression:</strong> Apply LoRA with rank 8-16 to low-utilization layers</li>
            <li><strong>Monitoring:</strong> Track condition numbers during training to detect instability early</li>
        </ol>
    </div>
    
    <footer style="text-align: center; margin-top: 40px; color: #7f8c8d;">
        <p>Generated by WeightScope - AI Model Weight Analysis Toolkit</p>
    </footer>
</body>
</html>
"""
    
    report_path = output_dir / "analysis_report.html"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    print(f"\nåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š:")
    print(f"  file://{report_path.absolute()}")
    print()


def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\n" + "="*80)
    print("WeightScope å¯è§†åŒ–åŠŸèƒ½æ¼”ç¤º")
    print("="*80)
    print("\nè¿™ä¸ªæ¼”ç¤ºå°†ç”Ÿæˆ 6 ç±»å®ç”¨å›¾è¡¨ï¼Œå¸®åŠ©ä½ è¯Šæ–­æ¨¡å‹é—®é¢˜\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("visualization_outputs")
    output_dir.mkdir(exist_ok=True)
    
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    try:
        demo_1_condition_number_heatmap()
        demo_2_quantization_risk_matrix()
        demo_3_rank_efficiency()
        demo_4_health_dashboard()
        demo_5_layer_details()
        demo_6_summary_report()
        
        print("=" * 80)
        print("âœ… æ‰€æœ‰å¯è§†åŒ–å·²å®Œæˆï¼")
        print("=" * 80)
        print(f"\næ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir.absolute()}/")
        print("\nç”Ÿæˆçš„å›¾è¡¨:")
        print("  1. condition_heatmap.png - æ¡ä»¶æ•°çƒ­åŠ›å›¾")
        print("  2. quantization_risk.png - é‡åŒ–é£é™©çŸ©é˜µ")
        print("  3. rank_efficiency.png - ç§©æ•ˆç‡åˆ†æ")
        print("  4. health_dashboard.png - å¥åº·ä»ªè¡¨ç›˜")
        print("  5. layer_details/*.png - å±‚çº§è¯¦ç»†åˆ†æ")
        print("  6. analysis_report.html - å®Œæ•´ HTML æŠ¥å‘Š")
        
        print(f"\nğŸ’¡ æç¤º: åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ {output_dir.absolute()}/analysis_report.html æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
